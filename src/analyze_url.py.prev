
# src/analyze_url.py (ãƒ‡ãƒãƒƒã‚°å¼·åŒ– & æ­£è¦åŒ–ç‰ˆ)
import os
import time
import re  # æ­£è¦è¡¨ç¾ã‚’è¿½åŠ 
import difflib
from playwright.sync_api import sync_playwright

AUTH_FILE = "auth.json"

def clean_text(text):
    """
    æ¯”è¼ƒã®ãŸã‚ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’ãã‚Œã„ã«ã™ã‚‹
    ï¼ˆã€ã€‘ã®ä¸­èº«ã‚„ã€(å†é€)ãªã©ã®ãƒã‚¤ã‚ºã‚’æ¶ˆã™ï¼‰
    """
    if not text: return ""
    # 1. æ”¹è¡Œã¨ç©ºç™½ã‚’è©°ã‚ã‚‹
    text = text.replace("\n", "").replace(" ", "").replace("ã€€", "")
    # 2. ã€ã€‡ã€‡ã€‘ã®ã‚ˆã†ãªéš…ä»˜ãæ‹¬å¼§ã‚’å‰Šé™¤
    text = re.sub(r'ã€.*?ã€‘', '', text)
    # 3. (å†é€) ãªã©ã‚’å‰Šé™¤
    text = re.sub(r'\(.*?\)', '', text)
    text = re.sub(r'ï¼ˆ.*?ï¼‰', '', text)
    return text

def fetch_job_text(target_url, target_subject=None):
    print(f"ğŸš€ ãƒ–ãƒ©ã‚¦ã‚¶èµ·å‹•: {target_url}")
    
    # æ¯”è¼ƒç”¨ã«ä»¶åã‚’ãã‚Œã„ã«ã—ã¦ãŠã
    clean_target = clean_text(target_subject) if target_subject else ""
    if target_subject:
        print(f"ğŸ” å…ƒã®ä»¶å: {target_subject[:20]}...")
        print(f"ğŸ§¹ æ¯”è¼ƒç”¨ã€€: {clean_target[:20]}...")

    extracted_text = ""

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False) 
        context = browser.new_context(storage_state=AUTH_FILE)
        page = context.new_page()

        try:
            page.goto(target_url)
            page.wait_for_load_state("domcontentloaded")

            if "messages" in page.url:
                print("ğŸ•µï¸ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‹ã‚‰æœ€é©ãªãƒªãƒ³ã‚¯ã‚’æ¢ç´¢...")
                
                links = page.locator(".p-messages-main a").all()
                
                best_link = None
                best_score = 0.0
                backup_link = None 

                print(f"ğŸ‘€ ç”»é¢å†…ã®ãƒªãƒ³ã‚¯æ•°: {len(links)}")

                for i, link in enumerate(links):
                    href = link.get_attribute("href")
                    # ç”»é¢ä¸Šã®è¦‹ãŸã¾ã¾ã®ãƒ†ã‚­ã‚¹ãƒˆ
                    raw_text = link.inner_text()
                    # æ¯”è¼ƒç”¨ã«ãã‚Œã„ã«ã™ã‚‹
                    text = clean_text(raw_text)
                    
                    if not href: continue
                    
                    # é™¤å¤–ãƒ­ã‚¸ãƒƒã‚¯
                    if (href in ["/messages", "#", "/"] or 
                        "agent_scouts" in href or 
                        "javascript" in href or 
                        ("job_offers" in href and "student" not in href)):
                        continue

                    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç¢ºä¿
                    if backup_link is None:
                        backup_link = link

                    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤ºï¼ˆã“ã‚Œã§ä½•ãŒè¦‹ãˆã¦ã„ã‚‹ã‹åˆ†ã‹ã‚‹ï¼ï¼‰
                    if target_subject:
                        similarity = difflib.SequenceMatcher(None, clean_target, text).ratio()
                        
                        # éƒ¨åˆ†ä¸€è‡´ãƒœãƒ¼ãƒŠã‚¹
                        if clean_target in text or text in clean_target:
                            similarity += 0.4
                        
                        # ä¸Šä½å€™è£œã ã‘ãƒ­ã‚°ã«å‡ºã™
                        if similarity > 0.3:
                            print(f"   [{i}] ä¸€è‡´åº¦:{similarity:.2f} | {text[:20]}... -> {href}")
                        
                        if similarity > best_score:
                            best_score = similarity
                            best_link = link
                
                target_link = None

                # åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
                if best_link and best_score > 0.4: # é–¾å€¤ã‚’å°‘ã—ä¸Šã’ã‚‹
                    print(f"âœ… ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç‰¹å®š (ã‚¹ã‚³ã‚¢:{best_score:.2f})")
                    target_link = best_link
                elif backup_link:
                    print(f"âš ï¸ åˆè‡´ã™ã‚‹ä»¶åãªã— (æœ€é«˜:{best_score:.2f})ã€‚ä¸€ç•ªä¸Šã‚’é–‹ãã¾ã™ã€‚")
                    target_link = backup_link
                else:
                    print("âŒ æœ‰åŠ¹ãªãƒªãƒ³ã‚¯ãŒä¸€ã¤ã‚‚è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚»ãƒ¬ã‚¯ã‚¿ãŒé–“é•ã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

                if target_link:
                    print(f"ğŸ–±ï¸ ã‚¯ãƒªãƒƒã‚¯å®Ÿè¡Œ: {target_link.get_attribute('href')}")
                    target_link.scroll_into_view_if_needed()
                    target_link.click()
                    page.wait_for_load_state("domcontentloaded")
                    page.wait_for_timeout(3000)

            print("ğŸ“„ ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºä¸­...")
            extracted_text = page.locator("body").inner_text()

        except Exception as e:
            print(f"âŒ ãƒ–ãƒ©ã‚¦ã‚¶æ“ä½œã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            browser.close()
    
    return extracted_text[:5000]

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨
    fetch_job_text("https://paiza.jp/messages?from=golden_scout", "ãƒ†ã‚¹ãƒˆä»¶å")
